{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf92ec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy Loss for test_pred1 and test_target1: 5.920933667691045\n",
      "Cross-Entropy Loss for test_pred2 and test_target2: 8.289306734767262\n",
      "Dice Loss for test_pred1 and test_target1: 0.5999998800000239\n",
      "Dice Loss for test_pred2 and test_target2: 0.5999998800000239\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from math import log\n",
    "\n",
    "\n",
    "test_pred1 = [1,0,1,0,1,0,0]\n",
    "test_pred2 = [1,1,0,1,0]\n",
    "test_target1 = [0,0,0,1,1,0,0]\n",
    "test_target2 = [0,0,1,1,0]\n",
    "\n",
    "\n",
    "# cross entropy\n",
    "def ce(pred, targ):\n",
    "\n",
    "    pred = [float(p) for p in pred]\n",
    "    targ = [float(t) for t in targ]\n",
    "    \n",
    "    # Calculate cross-entropy loss\n",
    "    loss = -sum(t * log(max(p, 1e-6)) + (1 - t) * log(max(1 - p, 1e-6)) for p, t in zip(pred, targ))\n",
    "    \n",
    "    return loss / len(pred)\n",
    "\n",
    "# dice loss\n",
    "def dl(pred, targ):\n",
    "    pred = [float(p) for p in pred]\n",
    "    targ = [float(t) for t in targ]\n",
    "    \n",
    "    # Calculate Dice coefficient\n",
    "    intersection = sum(p * t for p, t in zip(pred, targ))\n",
    "    dice_coeff = (2 * intersection + 1e-6) / (sum(pred) + sum(targ) + 1e-6)\n",
    "    \n",
    "    # Calculate Dice loss\n",
    "    loss = 1 - dice_coeff\n",
    "    \n",
    "    return loss\n",
    "\n",
    "print(\"Cross-Entropy Loss for test_pred1 and test_target1:\", ce(test_pred1, test_target1))\n",
    "print(\"Cross-Entropy Loss for test_pred2 and test_target2:\", ce(test_pred2, test_target2))\n",
    "print(\"Dice Loss for test_pred1 and test_target1:\", dl(test_pred1, test_target1))\n",
    "print(\"Dice Loss for test_pred2 and test_target2:\", dl(test_pred2, test_target2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a73333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.4372,  0.5410, -0.7114,  0.0496],\n",
      "          [-1.0471, -0.3032, -2.3385,  0.4909],\n",
      "          [-1.2547, -0.7022,  1.1577,  1.1411],\n",
      "          [-1.1810,  1.0437, -0.4040, -2.3348]],\n",
      "\n",
      "         [[-0.8528, -1.5593, -1.0323,  0.6387],\n",
      "          [-0.7896,  0.7512, -0.3808,  0.1616],\n",
      "          [ 0.6100, -0.1642, -0.7026,  1.7131],\n",
      "          [-1.3847,  0.5318, -0.1479,  0.0535]],\n",
      "\n",
      "         [[-0.3831,  0.2597,  0.2442,  0.2699],\n",
      "          [ 1.1634, -2.6126, -0.5483,  0.5152],\n",
      "          [-1.2074,  1.3672,  0.8899,  0.8036],\n",
      "          [-0.4986, -0.4400,  0.0515, -2.6332]]]], requires_grad=True)\n",
      "torch.Size([1, 3, 4, 4])\n",
      "tensor([[[1, 0, 1, 0],\n",
      "         [0, 1, 2, 0],\n",
      "         [1, 0, 2, 0],\n",
      "         [2, 0, 1, 2]]])\n",
      "torch.Size([1, 4, 4])\n",
      "tensor(1.2403, grad_fn=<NllLoss2DBackward0>)\n",
      "############\n",
      "tensor([[[[-0.4372,  0.5410, -0.7114,  0.0496],\n",
      "          [-1.0471, -0.3032, -2.3385,  0.4909],\n",
      "          [-1.2547, -0.7022,  1.1577,  1.1411],\n",
      "          [-1.1810,  1.0437, -0.4040, -2.3348]],\n",
      "\n",
      "         [[-0.8528, -1.5593, -1.0323,  0.6387],\n",
      "          [-0.7896,  0.7512, -0.3808,  0.1616],\n",
      "          [ 0.6100, -0.1642, -0.7026,  1.7131],\n",
      "          [-1.3847,  0.5318, -0.1479,  0.0535]],\n",
      "\n",
      "         [[-0.3831,  0.2597,  0.2442,  0.2699],\n",
      "          [ 1.1634, -2.6126, -0.5483,  0.5152],\n",
      "          [-1.2074,  1.3672,  0.8899,  0.8036],\n",
      "          [-0.4986, -0.4400,  0.0515, -2.6332]]]], requires_grad=True)\n",
      "torch.Size([1, 3, 4, 4])\n",
      "tensor([[[255,   0,   1,   0],\n",
      "         [  0,   1,   2,   0],\n",
      "         [  1,   0,   2,   0],\n",
      "         [  2,   0,   1,   2]]])\n",
      "torch.Size([1, 4, 4])\n",
      "tensor(1.2287, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example tensors\n",
    "pred = torch.randn(1, 3, 4, 4, requires_grad=True)  \n",
    "target = torch.randint(0, 3, (1, 4, 4)) \n",
    "print(pred)\n",
    "print(pred.shape)\n",
    "print(target)\n",
    "print(target.shape)\n",
    "\n",
    "# Use built-in ignore_index\n",
    "loss = F.cross_entropy(pred, target) # , ignore_index=255\n",
    "print(loss)\n",
    "print('############')\n",
    "target[0, 0, 0] = 255  # Let's say 255 is the ignore index\n",
    "print(pred)\n",
    "print(pred.shape)\n",
    "print(target)\n",
    "print(target.shape)\n",
    "loss = F.cross_entropy(pred, target, ignore_index=255)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95bd7b",
   "metadata": {},
   "source": [
    "### counts the number of pixels for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a622e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_id  class_name  pixel_val\n",
      "0         0  background        0.0\n",
      "1         1       upper      212.0\n",
      "2         2       lower      255.0\n",
      "3         3       tooth        NaN\n",
      "4         4        pulp      127.0\n",
      "5         5      dentin      170.0\n",
      "6         6      enamel       85.0\n",
      "7         7   composite       42.0\n",
      "############################\n",
      "Pixel counts for each class:\n",
      "background: 5161360.47715736\n",
      "upper: 97187.13197969543\n",
      "lower: 159645.91370558375\n",
      "tooth: 0.0\n",
      "pulp: 99224.96446700508\n",
      "dentin: 581722.0203045686\n",
      "enamel: 147300.38578680204\n",
      "composite: 38744.918781725886\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Path to the directory containing .png files\n",
    "annotation_dir = \"I:\\Datasets\\Hierarchical Datasets\\TL_pano\\processed\\labels\"\n",
    "\n",
    "# Path to the .csv file containing pixel values and class mappings\n",
    "csv_file = \"I:\\Datasets\\Hierarchical Datasets\\TL_pano\\processed\\class_map.csv\"\n",
    "\n",
    "# Load the class mapping from the .csv file\n",
    "class_mapping = pd.read_csv(csv_file)\n",
    "print(class_mapping)\n",
    "\n",
    "# Initialize a dictionary to store pixel counts for each class\n",
    "pixel_counts = {row['class_name']: 0 for _, row in class_mapping.iterrows()}\n",
    "num_imgs = 0\n",
    "# Traverse and process each .png file in the directory\n",
    "for file_name in os.listdir(annotation_dir):\n",
    "    if file_name.endswith(\".png\"):\n",
    "        num_imgs += 1\n",
    "        file_path = os.path.join(annotation_dir, file_name)\n",
    "        \n",
    "        # Load the image\n",
    "        image = Image.open(file_path)\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        # Count pixels for each class\n",
    "        for _, row in class_mapping.iterrows():\n",
    "            class_value = row['pixel_val']\n",
    "            pixel_counts[row['class_name']] += np.sum(image_array == class_value)\n",
    "print('############################')\n",
    "# Print the pixel counts for each class\n",
    "print(\"Pixel counts for each class:\")\n",
    "for class_name, count in pixel_counts.items():\n",
    "    print(f\"{class_name}: {count/num_imgs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2662d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 1, 1,  ..., 0, 1, 0],\n",
      "         [1, 1, 0,  ..., 0, 1, 0],\n",
      "         [1, 0, 1,  ..., 0, 0, 1],\n",
      "         ...,\n",
      "         [0, 0, 1,  ..., 1, 0, 0],\n",
      "         [0, 0, 1,  ..., 1, 0, 0],\n",
      "         [1, 0, 1,  ..., 1, 0, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 1, 0],\n",
      "         [0, 1, 1,  ..., 1, 0, 1],\n",
      "         [0, 1, 1,  ..., 0, 1, 1],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 1, 0,  ..., 0, 1, 0],\n",
      "         [0, 0, 1,  ..., 0, 1, 0]],\n",
      "\n",
      "        [[0, 0, 1,  ..., 1, 0, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 1],\n",
      "         [1, 0, 0,  ..., 1, 0, 1],\n",
      "         [0, 0, 1,  ..., 0, 0, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 0,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [0, 0, 0,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 0]],\n",
      "\n",
      "        [[1, 0, 1,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 1],\n",
      "         ...,\n",
      "         [1, 1, 0,  ..., 0, 0, 1],\n",
      "         [0, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 0,  ..., 1, 0, 0]],\n",
      "\n",
      "        [[1, 1, 0,  ..., 1, 1, 1],\n",
      "         [0, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 0, 1],\n",
      "         ...,\n",
      "         [1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 1],\n",
      "         [1, 1, 1,  ..., 0, 0, 1]]])\n",
      "torch.Size([10, 25, 25])\n",
      "tensor([[[0, 1, 0,  ..., 1, 0, 0],\n",
      "         [1, 0, 1,  ..., 0, 1, 0],\n",
      "         [1, 0, 0,  ..., 1, 0, 1],\n",
      "         ...,\n",
      "         [1, 1, 0,  ..., 0, 1, 1],\n",
      "         [0, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 1]],\n",
      "\n",
      "        [[1, 0, 1,  ..., 1, 0, 1],\n",
      "         [0, 1, 1,  ..., 1, 0, 0],\n",
      "         [0, 0, 1,  ..., 0, 1, 1],\n",
      "         ...,\n",
      "         [0, 1, 1,  ..., 1, 1, 0],\n",
      "         [0, 0, 0,  ..., 0, 1, 0],\n",
      "         [0, 1, 0,  ..., 1, 0, 1]],\n",
      "\n",
      "        [[0, 1, 0,  ..., 1, 1, 0],\n",
      "         [0, 0, 1,  ..., 1, 0, 1],\n",
      "         [1, 0, 1,  ..., 1, 0, 1],\n",
      "         ...,\n",
      "         [0, 1, 0,  ..., 0, 0, 1],\n",
      "         [0, 1, 1,  ..., 0, 0, 1],\n",
      "         [0, 0, 0,  ..., 0, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 1, 0, 1],\n",
      "         [0, 1, 1,  ..., 1, 0, 1],\n",
      "         [0, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 0, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 1, 0],\n",
      "         [1, 0, 0,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 1,  ..., 1, 0, 1],\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 1, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [0, 1, 0,  ..., 0, 0, 1],\n",
      "         [0, 0, 1,  ..., 1, 1, 0]],\n",
      "\n",
      "        [[0, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 1, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 0, 1,  ..., 1, 0, 1],\n",
      "         [1, 1, 1,  ..., 0, 0, 1]]])\n",
      "torch.Size([10, 25, 25])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Banksy\\AppData\\Local\\Temp\\ipykernel_6852\\2990729996.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = tensor(pred)\n",
      "C:\\Users\\Banksy\\AppData\\Local\\Temp\\ipykernel_6852\\2990729996.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = tensor(target)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3376)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import randint, tensor\n",
    "import torchmetrics\n",
    "target = randint(0, 2, (10, 25, 25))\n",
    "pred = randint(0, 2, (10, 25, 25))\n",
    "pred = tensor(pred)\n",
    "target = tensor(target)\n",
    "print(pred)\n",
    "print(pred.shape)\n",
    "print(target)\n",
    "print(target.shape)\n",
    "\n",
    "jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=2)\n",
    "jaccard(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1cff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
